%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Guillaume Gautier at 2018-08-02 10:32:48 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{DuBa16,
	Abstract = {We propose a new class of determinantal point processes (DPPs) which can be manipulated for inference and parameter learning in potentially sublinear time in the number of items. This class, based on a specific low-rank factorization of the marginal kernel, is particularly suited to a subclass of continuous DPPs and DPPs defined on exponentially many items. We apply this new class to modelling text documents as sampling a DPP of sentences, and propose a conditional maximum likelihood formulation to model topic proportions, which is made possible with no approximation for our class of DPPs. We present an application to document summarization with a DPP on {\$}2{\^{}}{\{}500{\}}{\$} items.},
	Archiveprefix = {arXiv},
	Arxivid = {1610.05925},
	Author = {Dupuy, C. and Bach, F.},
	Date-Added = {2018-08-02 08:28:47 +0000},
	Date-Modified = {2018-08-02 08:28:47 +0000},
	Eprint = {1610.05925},
	File = {:Users/ggautier/Documents/Mendeley{\_}Desktop/Dupuy, Bach - 2016 - Learning Determinantal Point Processes in Sublinear Time.pdf:pdf},
	Journal = {arXiv preprint arXiv:1610.05925},
	Title = {Learning Determinantal Point Processes in Sublinear Time},
	Url = {http://arxiv.org/abs/1610.05925},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1610.05925}}

@inproceedings{GaPaKo16,
	Abstract = {Determinantal point processes (DPPs) have garnered attention as an elegant probabilistic model of set diversity. They are useful for a number of subset selection tasks, including product recommendation. DPPs are parametrized by a positive semi-definite kernel matrix. In this work we present a new method for learning the DPP kernel from observed data using a low-rank factorization of this kernel. We show that this low-rank factorization enables a learning algorithm that is nearly an order of magnitude faster than previous approaches, while also providing for a method for computing product recommendation predictions that is far faster (up to 20x faster or more for large item catalogs) than previous techniques that involve a full-rank DPP kernel. Furthermore, we show that our method provides equivalent or sometimes better predictive performance than prior full-rank DPP approaches, and better performance than several other competing recommendation methods in many cases. We conduct an extensive experimental evaluation using several real-world datasets in the domain of product recommendation to demonstrate the utility of our method, along with its limitations.},
	Archiveprefix = {arXiv},
	Arxivid = {1602.05436},
	Author = {Gartrell, M. and Paquet, U. and Koenigstein, N.},
	Booktitle = {AAAI Conference on Artificial Intelligence},
	Date-Added = {2018-08-02 08:28:42 +0000},
	Date-Modified = {2018-08-02 08:28:42 +0000},
	Eprint = {1602.05436},
	Pages = {1912--1918},
	Title = {Low-Rank Factorization of Determinantal Point Processes for Recommendation},
	Url = {http://arxiv.org/abs/1602.05436},
	Year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1602.05436}}

@article{KaDeKo16,
	Abstract = {Gaussian Process bandit optimization has emerged as a powerful tool for optimizing noisy black box functions. One example in machine learning is hyper-parameter optimization where each evaluation of the target function requires training a model which may involve days or even weeks of computation. Most methods for this so-called "Bayesian optimization" only allow sequential exploration of the parameter space. However, it is often desirable to propose batches or sets of parameter values to explore simultaneously, especially when there are large parallel processing facilities at our disposal. Batch methods require modeling the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. In this paper, we propose a new approach for parallelizing Bayesian optimization by modeling the diversity of a batch via Determinantal point processes (DPPs) whose kernels are learned automatically. This allows us to generalize a previous result as well as prove better regret bounds based on DPP sampling. Our experiments on a variety of synthetic and real-world robotics and hyper-parameter optimization tasks indicate that our DPP-based methods, especially those based on DPP sampling, outperform state-of-the-art methods.},
	Author = {Kathuria, T. and Deshpande, A. and Kohli, P.},
	Date-Added = {2018-08-02 08:28:35 +0000},
	Date-Modified = {2018-08-02 08:28:35 +0000},
	File = {:Users/ggautier/Documents/Mendeley{\_}Desktop/Kathuria, Deshpande, Kohli - Unknown - Batched Gaussian Process Bandit Optimization via Determinantal Point Processes.pdf:pdf},
	Journal = {Neural Information Processing Systems},
	Pages = {pp. 4206-4214},
	Title = {Batched Gaussian Process Bandit Optimization via Determinantal Point Processes},
	Url = {http://arxiv.org/abs/1611.04088},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1611.04088}}

@book{PaBe11,
	Author = {R.K. Pathria and P.D. Beale},
	title = {Statistical Mechanics},
	Year = {2011},
	Publisher = {Academic Press},
	Address = {Boston},
	Edition = {Third},
	Doi = {10.1016/B978-0-12-382188-1.00020-7},
	Isbn = {978-0-12-382188-1},
	Url = {http://www.sciencedirect.com/science/article/pii/B9780123821881000207},
}

@inproceedings{AnGhRe16,
	Arxivid = {1602.05242},
	Author = {Anari, N. and Gharan, S O and Rezaei, A},
	Booktitle = {Conference on Learning Theory},
	Pages = {23--26},
	Title = {{Monte-Carlo Markov chain algorithms for sampling strongly Rayleigh distributions and determinantal point processes}},
	Url = {https://arxiv.org/abs/1602.05242},
	Year = {2016},
	Bdsk-Url-1 = {https://arxiv.org/abs/1602.05242}}

@inproceedings{AfKuFo13,
	Abstract = {Determinantal point processes (DPPs) are appealing models for subset selection prob-lems where diversity is desired. They offer surprisingly efficient inference, including sam-pling in O(N 3) time and O(N 2) space, where N is the number of base items. However, in some applications, N may grow so large that sampling from a DPP becomes compu-tationally infeasible. This is especially true in settings where the DPP kernel matrix can-not be represented by a linear decomposition of low-dimensional feature vectors. In these cases, we propose applying the Nystr{\"{o}}m approximation to project the kernel matrix into a low-dimensional space. While theoretical guarantees for the Nystr{\"{o}}m approximation in terms of standard matrix norms have been previously established, we are concerned with probabilistic measures, like total variation dis-tance between the DPP and its Nystr{\"{o}}m ap-proximation, that behave quite differently. In this paper we derive new error bounds for the Nystr{\"{o}}m-approximated DPP and present em-pirical results to corroborate them. We then demonstrate the Nystr{\"{o}}m-approximated DPP by applying it to a motion capture summa-rization task.},
	Address = {Scottsdale, AZ, USA},
	Author = {Affandi, R. and Kulesza, A. and Fox, E. B and Taskar, B.},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Keywords = {dblp},
	Pages = {85--98},
	Title = {{Nystrom Approximation for Large-Scale Determinantal Processes.}},
	Url = {http://jmlr.org/proceedings/papers/v31/affandi13a.html},
	Volume = {31},
	Year = {2013},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v31/affandi13a.html}}

@article{AvGa13,
	Abstract = {Consider a finite weighted oriented graph. We study a probability measure on the set of spanning rooted oriented forests on the graph. We prove that the set of roots sampled from this measure is a determinantal process, characterized by a possibly non-symmetric kernel with complex eigenvalues. We then derive several results relating this measure to the Markov process associated with the starting graph, to the spectrum of its generator and to hitting times of subsets of the graph. In particular, the mean hitting time of the set of roots turns out to be independent of the starting point, conditioning or not to a given number of roots. Wilson's algorithm provides a way to sample this measure and, in absence of complex eigenvalues of the generator, we explain how to get samples with a number of roots approximating a prescribed integer. We also exploit the properties of this measure to give some probabilistic insight into the proof of an algebraic result due to Micchelli and Willoughby [13]. Further, we present two different related coalescence and fragmentation processes.},
	Author = {Avena, L. and Gaudilliere, A.},
	Journal = {e-prints},
	Keywords = {05C81,05C85 Keywords,15A15,15A18,60J20,Finite networks,MSC 2010,Wilson's algorithm,coalescence and frag-mentation,determinantal processes,hit-ting times,local equilibria,primary,random partitions,random sets,secondary,spanning forests},
	Title = {{On some random forests with determinantal roots}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.740.6173{\&}rep=rep1{\&}type=pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.740.6173%7B%5C&%7Drep=rep1%7B%5C&%7Dtype=pdf}}

@article{BaHa16,
	Abstract = {We show that repulsive random variables can yield Monte Carlo methods with faster convergence rates than the typical {\$}N{\^{}}{\{}-1/2{\}}{\$}, where {\$}N{\$} is the number of integrand evaluations. More precisely, we propose stochastic numerical quadratures involving determinantal point processes associated with multivariate orthogonal polynomials, and we obtain root mean square errors that decrease as {\$}N{\^{}}{\{}-(1+1/d)/2{\}}{\$}, where {\$}d{\$} is the dimension of the ambient space. First, we prove a central limit theorem (CLT) for the linear statistics of a class of determinantal point processes, when the reference measure is a product measure supported on a hypercube, which satisfies the Nevai-class regularity condition, a result which may be of independent interest. Next, we introduce a Monte Carlo method based on these determinantal point processes, and prove a CLT with explicit limiting variance for the quadrature error, when the reference measure satisfies a stronger regularity condition. As a corollary, by taking a specific reference measure and using a construction similar to importance sampling, we obtain a general Monte Carlo method, which applies to any measure with continuously derivable density. Loosely speaking, our method can be interpreted as a stochastic counterpart to Gaussian quadrature, which, at the price of some convergence rate, is easily generalizable to any dimension and has a more explicit error term.},
	Archiveprefix = {arXiv},
	Arxivid = {1605.00361},
	Author = {Bardenet, R. and Hardy, A.},
	Eprint = {1605.00361},
	Journal = {ArXiv e-prints},
	Title = {{Monte Carlo with Determinantal Point Processes}},
	Year = {2016}}

@article{BoDiFu09,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2009arXiv0904.3740B},
	Archiveprefix = {arXiv},
	Author = {Borodin, A. and Diaconis, P. and Fulman, J.},
	Date-Modified = {2018-08-02 08:13:45 +0000},
	Eprint = {0904.3740},
	Journal = {ArXiv e-prints},
	Keywords = {Mathematics - Probability, Mathematics - Combinatorics},
	Month = {apr},
	Primaryclass = {math.PR},
	Title = {{On adding a list of numbers (and other one-dependent determinantal processes)}},
	Year = {2009}}

@article{DFL13,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1311.1027D},
	Archiveprefix = {arXiv},
	Author = {Decreusefond, L. and Flint, I. and Low, K.~C.},
	Eprint = {1311.1027},
	Journal = {ArXiv e-prints},
	Keywords = {Mathematics - Probability, Mathematics - Statistics Theory},
	Month = {nov},
	Primaryclass = {math.PR},
	Title = {{Perfect Simulation of Determinantal Point Processes}},
	Year = {2013}}

@article{DuEd02,
	Author = {Dumitriu, I. and Edelman, A.},
	Journal = {Journal of Mathematical Physics},
	Number = {11},
	Pages = {5830-5847},
	Title = {Matrix models for beta ensembles},
	Url = {https://sites.math.washington.edu/~dumitriu/JMathPhys_43_5830.pdf},
	Volume = {43},
	Year = {2002},
	Bdsk-Url-1 = {https://sites.math.washington.edu/~dumitriu/JMathPhys_43_5830.pdf}}

@article{DuEd15,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Archiveprefix = {arXiv},
	Author = {Dubbs, A. and Edelman, A.},
	Eprint = {1502.04931},
	Journal = {ArXiv e-prints},
	Keywords = {Mathematics - Probability},
	Month = {feb},
	Primaryclass = {math.PR},
	Title = {{Infinite Random Matrix Theory, Tridiagonal Bordered Toeplitz Matrices, and the Moment Problem}},
	Year = {2015}}

@inproceedings{GaBaVa17,
	Abstract = {Determinantal point processes (DPPs) are distributions over sets of items that model diversity using kernels. Their applications in machine learning include summary extraction and recommendation systems. Yet, the cost of sampling from a DPP is prohibitive in large-scale applications, which has triggered an effort towards efficient approximate samplers. We build a novel MCMC sampler that combines ideas from combinatorial geometry, linear programming, and Monte Carlo methods to sample from DPPs with a fixed sample cardinality, also called projection DPPs. Our sampler leverages the ability of the hit-and-run MCMC kernel to efficiently move across convex bodies. Previous theoretical results yield a fast mixing time of our chain when targeting a distribution that is close to a projection DPP, but not a DPP in general. Our empirical results demonstrate that this extends to sampling projection DPPs, i.e., our sampler is more sample-efficient than previous approaches which in turn translates to faster convergence when dealing with costly-to-evaluate functions, such as summary extraction in our experiments.},
	Address = {Sydney, Australia},
	Archiveprefix = {arXiv},
	Arxivid = {1705.10498},
	Author = {Gautier, G. and Bardenet, R. and Valko, M.},
	Booktitle = {International Conference on Machine Learning},
	Eprint = {1705.10498},
	Pages = {1223--1232},
	Publisher = {PMLR},
	Title = {{Zonotope hit-and-run for efficient sampling from projection DPPs}},
	Url = {http://proceedings.mlr.press/v70/gautier17a/gautier17a.pdf},
	Year = {2017},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v70/gautier17a/gautier17a.pdf}}

@article{Gil14,
	Author = {Gillenwater, J.},
	Journal = {Publicly Accessible Penn Dissertations. 1285.},
	Title = {{Approximate inference for determinantal point processes}},
	Url = {https://repository.upenn.edu/edissertations/1285},
	Year = {2014},
	Bdsk-Url-1 = {https://repository.upenn.edu/edissertations/1285}}

@article{HKPV06,
	Arxivid = {0503110},
	Author = {Hough, J. B. and Krishnapur, M. and Peres, Y. and Virag, B.},
	Journal = {Probability surveys},
	Title = {{Determinantal processes and independence}},
	Url = {http://arxiv.org/abs/0503110},
	Year = {2006},
	Bdsk-Url-1 = {http://arxiv.org/abs/0503110}}

@article{KiNe04,
	Author = {Killip, R. and Nenciu, I.},
	Doi = {10.1155/S1073792804141597},
	Journal = {International Mathematics Research Notices},
	Number = {50},
	Pages = {2665-2701},
	Title = {Matrix models for circular ensembles},
	Url = {+ http://dx.doi.org/10.1155/S1073792804141597},
	Volume = {2004},
	Year = {2004},
	Bdsk-Url-1 = {+%20http://dx.doi.org/10.1155/S1073792804141597},
	Bdsk-Url-2 = {https://doi.org/10.1155/S1073792804141597}}

@article{LaGaDe18,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180208429L},
	Archiveprefix = {arXiv},
	Author = {Launay, C. and Galerne, B. and Desolneux, A.},
	Eprint = {1802.08429},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Machine Learning},
	Month = {feb},
	Primaryclass = {stat.ML},
	Title = {{Exact Sampling of Determinantal Point Processes without Eigendecomposition}},
	Year = {2018}}

@article{KuTa12,
	Abstract = {Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. We provide a gentle introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and show how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories.},
	Annote = {NULL},
	Archiveprefix = {arXiv},
	Arxivid = {1207.6083},
	Author = {Kulesza, A. and Taskar, B.},
	Doi = {10.1561/2200000044},
	Eprint = {1207.6083},
	Issn = {1935-8237},
	Journal = {Foundations and Trends in Machine Learning},
	Month = {jul},
	Number = {2-3},
	Pages = {123--286},
	Title = {{Determinantal Point Processes for Machine Learning}},
	Volume = {5},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1561/2200000044}}

@article{Joh06,
	Abstract = {We survey recent results on determinantal processes, random growth, random tilings and their relation to random matrix theory.},
	Archiveprefix = {arXiv},
	Arxivid = {math-ph/0510038},
	Author = {Johansson, K.},
	Doi = {10.1016/S0924-8099(06)80038-7},
	Eprint = {0510038},
	File = {:Users/ggautier/Library/Application Support/Mendeley Desktop/Downloaded/Johansson - 2006 - Course 1 Random matrices and determinantal processes.pdf:pdf},
	Issn = {09248099},
	Journal = {Les Houches Summer School Proceedings},
	Number = {C},
	Pages = {1--56},
	Primaryclass = {math-ph},
	Title = {{Course 1 Random matrices and determinantal processes}},
	Volume = {83},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1016/S0924-8099(06)80038-7}}

@article{Kon05,
	Author = {K{\"o}nig, W.},
	Doi = {10.1214/154957805100000177},
	Fjournal = {Probability Surveys},
	Journal = {Probab. Surveys},
	Pages = {385--447},
	Publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
	Title = {Orthogonal polynomial ensembles in probability theory},
	Url = {https://doi.org/10.1214/154957805100000177},
	Volume = {2},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1214/154957805100000177}}

@article{LaMoRu15,
	Abstract = {Statistical models and methods for determinantal point processes (DPPs) seem largely unexplored. We demonstrate that DPPs provide useful models for the description of spatial point pattern datasets where nearby points repel each other. Such data are usually modelled by Gibbs point processes, where the likelihood and moment expressions are intractable and simulations are time consuming. We exploit the appealing probabilistic properties of DPPs to develop parametric models, where the likelihood and moment expressions can be easily evaluated and realizations can be quickly simulated. We discuss how statistical inference is conducted using the likelihood or moment properties of DPP models, and we provide freely available software for simulation and statistical inference.},
	Archiveprefix = {arXiv},
	Arxivid = {1205.4818},
	Author = {Lavancier, F. and Moller, K. and Rubak, E.},
	Doi = {10.1111/rssb.12096},
	Eprint = {1205.4818},
	Issn = {14679868},
	Journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
	Keywords = {Maximum-likelihood-based inference,Point process density,Product densities,Repulsiveness,Simulation,Spectral approach},
	Number = {4},
	Pages = {853--877},
	Title = {{Determinantal point process models and statistical inference}},
	Volume = {77},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1111/rssb.12096}}

@inproceedings{LiJeSr17,
	Abstract = {We study dual volume sampling, a method for selecting k columns from an n*m short and wide matrix (n {\textless}= k {\textless}= m) such that the probability of selection is proportional to the volume of the parallelepiped spanned by the rows of the induced submatrix. This method was studied in [3], who motivated it as a promising method for column subset selection. However, the development of polynomial time sampling algorithms -- exact or approximate -- has been since open. We close this open problem by presenting (i) an exact (randomized) polynomial time sampling algorithm; (ii) its derandomization that samples subsets satisfying the desired properties deterministically; and (iii) an efficient approximate sampling procedure using Markov chains that are provably fast mixing. Our algorithms can thus benefit downstream applications of dual volume sampling, such as column subset selection and experimental design.},
	Address = {Long Beach, CA, USA},
	Annote = {NULL},
	Archiveprefix = {arXiv},
	Arxivid = {1703.02674},
	Author = {Li, C. and Jegelka, S. and Sra, S.},
	Booktitle = {Neural Information Processing Systems},
	Eprint = {1703.02674},
	Month = {mar},
	Title = {{Column Subset Selection via Polynomial Time Dual Volume Sampling}},
	Year = {2017}}

@inproceedings{LiJeSr16a,
	Abstract = {Determinantal Point Processes (DPPs) provide probabilistic models over discrete sets of items that help model repulsion and diversity. Applicability of DPPs to large sets of data is, however, hindered by the expensive matrix operations involved, especially when sampling. We therefore propose a new efficient approximate two-stage sampling algorithm for discrete k-DPPs. As opposed to previous approximations, our algorithm aims at minimizing the variational distance to the original distribution. Experiments indicate that the resulting sampling algorithm works well on large data and yields more accurate samples than previous approaches.},
	Address = {Cadiz, Spain},
	Archiveprefix = {arXiv},
	Arxivid = {1509.01618},
	Author = {Li, C. and Jegelka, S. and Sra, S.},
	Booktitle = {International Conference on Artificial Intelligence and Statistics},
	Eprint = {1509.01618},
	Pages = {1--14},
	Title = {{Efficient Sampling for k-Determinantal Point Processes}},
	Url = {http://proceedings.mlr.press/v51/li16f.pdf},
	Volume = {51},
	Year = {2016},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v51/li16f.pdf}}

@inproceedings{LiJeSr16b,
	Abstract = {The Nystr{\"{o}}m method has long been popular for scaling up kernel methods. Its theoretical guarantees and empirical performance rely critically on the quality of the landmarks selected. We study landmark selection for Nystr{\"{o}}om using Determinantal Point Processes (DPPs), discrete probability models that allow tractable generation of diverse samples. We prove that landmarks selected via DPPs guarantee bounds on approximation errors; subsequently, we analyze implications for kernel ridge regression. Contrary to prior reservations due to cubic complexity of DPPsampling, we show that (under certain conditions) Markov chain DPP sampling requires only linear time in the size of the data. We present several empirical results that support our theoretical analysis, and demonstrate the superior performance of DPP-based landmark selection compared with existing approaches.},
	Address = {New York, USA},
	Archiveprefix = {arXiv},
	Arxivid = {1603.06052},
	Author = {Li, C. and Jegelka, S. and Sra, S.},
	Booktitle = {International Conference on Machine Learning},
	Eprint = {1603.06052},
	Isbn = {9781510829008},
	Pages = {2061--2070},
	Title = {{Fast DPP Sampling for Nystr{\"{o}}om with Application to Kernel Methods}},
	Url = {http://proceedings.mlr.press/v48/lih16.html},
	Volume = {48},
	Year = {2016},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v48/lih16.html}}

@inproceedings{LiJeSr16c,
	Abstract = {We study probability measures induced by set functions with constraints. Such measures arise in a variety of real-world settings, where prior knowledge, resource limitations, or other pragmatic considerations impose constraints. We consider the task of rapidly sampling from such constrained measures, and develop fast Markov chain samplers for them. Our first main result is for MCMC sampling from Strongly Rayleigh (SR) measures, for which we present sharp polynomial bounds on the mixing time. As a corollary, this result yields a fast mixing sampler for Determinantal Point Processes (DPPs), yielding (to our knowledge) the first provably fast MCMC sampler for DPPs since their inception over four decades ago. Beyond SR measures, we develop MCMC samplers for probabilistic models with hard constraints and identify sufficient conditions under which their chains mix rapidly. We illustrate our claims by empirically verifying the dependence of mixing times on the key factors governing our theoretical bounds.},
	Address = {Barcelona, Spain},
	Archiveprefix = {arXiv},
	Arxivid = {1608.01008},
	Author = {Li, C. and Jegelka, S. and Sra, S.},
	Booktitle = {Neural Information Processing Systems},
	Eprint = {1608.01008},
	Issn = {10495258},
	Title = {{Fast Mixing Markov Chains for Strongly Rayleigh Measures, DPPs, and Constrained Sampling}},
	Url = {https://papers.nips.cc/paper/6182-fast-mixing-markov-chains-for-strongly-rayleigh-measures-dpps-and-constrained-sampling},
	Year = {2016},
	Bdsk-Url-1 = {https://papers.nips.cc/paper/6182-fast-mixing-markov-chains-for-strongly-rayleigh-measures-dpps-and-constrained-sampling}}

@article{LiJeSr16d,
	Abstract = {In this note we consider sampling from (non-homogeneous) strongly Rayleigh probability measures. As an important corollary, we obtain a fast mixing Markov Chain sampler for Determinantal Point Processes.},
	Archiveprefix = {arXiv},
	Arxivid = {1607.03559},
	Author = {Li, C. and Jegelka, S. and Sra, S.},
	Eprint = {1607.03559},
	Journal = {ArXiv e-prints},
	Title = {Fast Sampling for Strongly Rayleigh Measures with Application to Determinantal Point Processes},
	Year = {2016}}

@article{Mac75,
	Abstract = {The structure of the probability space associated with a general point process, when regarded as a counting process, is reviewed using the coincidence formalism. The rest of the paper is devoted to the class of regular point processes for which all coincidence probabilities admit densities. It is shown that their distribution is completely specified by the system of coincidence densities. The specification formalism is stressed for 'completely' regular point processes. A construction theorem gives a characterization of the system of coincidence densities of such a process. It permits the study of most models of point processes. New results on the photon process, a particular type of conditioned Poisson process, are derived. New examples are exhibited, including the Gauss-Poisson process and the 'fermion' process that is suitable whenever the points are repulsive.},
	Author = {Macchi, O.},
	Issn = {00018678},
	Journal = {Advances in Applied Probability},
	Number = {1},
	Pages = {83-122},
	Publisher = {Applied Probability Trust},
	Title = {The Coincidence Approach to Stochastic Point Processes},
	Url = {http://www.jstor.org/stable/1425855},
	Volume = {7},
	Year = {1975},
	Bdsk-Url-1 = {http://www.jstor.org/stable/1425855}}

@article{Mez06,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2006math.ph...9050M},
	Author = {Mezzadri, F.},
	Eprint = {math-ph/0609050},
	Journal = {ArXiv Mathematical Physics e-prints},
	Keywords = {Mathematical Physics, Mathematics - Numerical Analysis, 1502,15A52, 65F25},
	Month = {sep},
	Title = {{How to generate random matrices from the classical compact groups}},
	Year = {2006}}

@book{MoWa04,
	Abstract = {Spatial point processes play a fundamental role in spatial statistics and today they are an active area of research with many new applications. Although other published works address different aspects of spatial point processes, most of the classical literature deals only with nonparametric methods, and a thorough treatment of the theory and applications of simulation-based inference is difficult to find. Written by researchers at the top of the field, this book collects and unifies recent theoretical advances and examples of applications. The authors examine Markov chain Monte Carlo algorithms and explore one of the most important recent developments in MCMC: perfect simulation procedures.},
	Author = {Moller, J. and Waagepetersen, R. R.},
	Doi = {10.1201/9780203496930},
	File = {:Users/ggautier/Documents/Mendeley Desktop/M{\o}ller, Waagepetersen - 2004 - Statistical inference and simulation for spatial point processes.pdf:pdf},
	Isbn = {1584882654},
	Issn = {0277-6715},
	Keywords = {point processes,spatial analysis (Statistics)},
	Pages = {320},
	Publisher = {CHAPMAN & HALL/CRC},
	Title = {{Statistical inference and simulation for spatial point processes}},
	Volume = {23},
	Year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1201/9780203496930}}

@article{RuSa96,
	author = "Rudnick, Z. and Sarnak, P.",
	doi = "10.1215/S0012-7094-96-08115-6",
	fjournal = "Duke Mathematical Journal",
	journal = "Duke Math. J.",
	number = "2",
	pages = "269--322",
	publisher = "Duke University Press",
	title = "Zeros of principal L-functions and random matrix theory",
	volume = "81",
	year = "1996"
}

@article{Sos00,
	Abstract = {This paper contains an exposition of both recent and rather old results on determinantal random point fields. We begin with some general theorems includ- ing proofs of necessary and sufficient conditions for the existence of a determinantal random point field with Hermitian kernel and of a criterion for weak convergence of its distribution. In the second section we proceed with examples of determinantal random fields in quantum mechanics, statistical mechanics, random matrix theory, probability theory, representation theory, and ergodic theory. In connection with the theory of renewal processes, we characterize all Hermitian determinantal random point fields on R1 and Z1 with independent identically distributed spacings. In the third section we study translation-invariant determinantal random point fields and prove the mixing property for arbitrary multiplicity and the absolute continuity of the spectra. In the last section we discuss proofs of the central limit theorem for the number of particles in a growing box and of the functional central limit theorem for the empirical distribution function of spacings.},
	Archiveprefix = {arXiv},
	Arxivid = {math/0002099v4},
	Author = {Soshnikov, A.},
	Doi = {10.1070/RM2000v055n05ABEH000321},
	Eprint = {math/0002099v4},
	Issn = {0042-1316},
	Journal = {Russian Mathematical Surveys},
	Number = {5},
	Pages = {923--975},
	Primaryclass = {math},
	Title = {{Determinantal random point fields}},
	Volume = {55},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1070/RM2000v055n05ABEH000321}}

@article{TrAmBa17a,
	Abstract = {We present a new random sampling strategy for k-bandlimited signals defined on graphs, based on determinantal point processes (DPP). For small graphs, ie, in cases where the spectrum of the graph is accessible, we exhibit a DPP sampling scheme that enables perfect recovery of bandlimited signals. For large graphs, ie, in cases where the graph's spectrum is not accessible, we investigate, both theoretically and empirically, a sub-optimal but much faster DPP based on loop-erased random walks on the graph. Preliminary experiments show promising results especially in cases where the number of measurements should stay as small as possible and for graphs that have a strong community structure. Our sampling scheme is efficient and can be applied to graphs with up to {\$}10{\^{}}6{\$} nodes.},
	Archiveprefix = {arXiv},
	Arxivid = {1703.01594},
	Author = {Tremblay, N. and Amblard, P. O. and Barthelmé, S.},
	Eprint = {1703.01594},
	Journal = {ArXiv e-prints},
	Title = {{Graph sampling with determinantal processes}},
	Year = {2017}}

@inproceedings{TrBaAm17b,
	Abstract = {R{\'e}sum{\'e} -- Nous consid{\'e}rons l echantillonnage de signaux sur graph{\`e} a bande limit{\'e}e k , i . e . , les combinaisons lin{\'e}aires des k premiers modes de Fourier du graphe . Il existe k noeuds du graphe qui permettent leur reconstruction parfaite , les trouver n{\'e}cessite cependant une diagonalisation partielle de la matrice laplacienne , trop co{\^{u}}teus{\`e} a grande dimension . Nous proposons une nouvelle m{\'e}thode rapide d echantillonnage bas{\'e}e sur des processus d{\'e}terminantaux qui permet la reconstructio a partir d ' un nombre d echantillons de l ' ordre de k . Abstract -- We consider the problem of sampling k - bandlimited graph signals , i . e . , linear combinations of the first k graph Fourier modes . We know that a set of k nodes embedding all k - bandlimited signals always exists , thereby enabling their perfect reconstruction after sampling . Unfortunately , to exhibit such a set , one needs to partially diagonalize the graph Laplacian , which becomes prohibitive at large scale . We propose a novel strategy based on determinantal point processes that side - steps partial diagonalisation and enables reconstruction with only O (k) samples .},
	Archiveprefix = {arXiv},
	Arxivid = {1704.02239},
	Author = {Tremblay, N. and Barthelmé, S. and Amblard, P. O.},
	Booktitle = {GRETSI},
	Eprint = {1704.02239},
	Title = {{{\'{E}}chantillonnage de signaux sur graphes via des processus d{\'e}terminantaux}},
	Url = {https://hal.archives-ouvertes.fr/hal-01503736},
	Year = {2017}
	}

@ARTICLE{TrBaAm18,
   author = {{Tremblay}, N. and {Barthelme}, S. and {Amblard}, P.-O.},
    title = "{Optimized Algorithms to Sample Determinantal Point Processes}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1802.08471},
 primaryClass = "stat.CO",
 keywords = {Statistics - Computation, Computer Science - Learning, Statistics - Machine Learning},
     year = 2018,
    month = feb,
   url = {https://arxiv.org/abs/1802.08471},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Wig67,
	Author = {Wigner, E.},
	Doi = {10.1137/1009001},
	Eprint = {https://doi.org/10.1137/1009001},
	Journal = {SIAM Review},
	Number = {1},
	Pages = {1--23},
	Title = {Random Matrices in Physics},
	Url = {https://doi.org/10.1137/1009001},
	Volume = {9},
	Year = {1967}
	}
